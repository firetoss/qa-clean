"""
Stage4 èšç±»æ¨¡å— - NetworkXå¼•æ“å®ç° (CPU/GPUæ··åˆåŠ é€Ÿ)

åŸºäºNetworkXå’ŒcuGraphçš„é«˜çº§èšç±»ç®—æ³•ï¼Œæä¾›æœ€é«˜è´¨é‡çš„ç¤¾åŒºå‘ç°èƒ½åŠ›ã€‚

ğŸš€ **GPUåŠ é€Ÿç‰¹æ€§ (NEW)**:
- GPUä¼˜å…ˆï¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä¼˜å…ˆä½¿ç”¨RAPIDS cuGraph
- æ€§èƒ½æå‡ï¼šç›¸æ¯”CPUå®ç°10-100xåŠ é€Ÿ
- è‡ªåŠ¨å›é€€ï¼šGPUå¤±è´¥æ—¶æ— ç¼å›é€€åˆ°CPUè·¯å¾„
- å†…å­˜ä¼˜åŒ–ï¼šGPUå†…å­˜ç®¡ç†å’Œæ•°æ®ä¼ è¾“ä¼˜åŒ–

ğŸ’¡ **æ ¸å¿ƒç®—æ³•**:
1. Leidenç®—æ³•ï¼šæœ€å…ˆè¿›çš„ç¤¾åŒºæ£€æµ‹ï¼Œè´¨é‡ä¼˜äºLouvain
2. Louvainç®—æ³•ï¼šç»å…¸çš„æ¨¡å—åº¦ä¼˜åŒ–ç®—æ³•  
3. è¿é€šåˆ†é‡ï¼šåŸºç¡€çš„å›¾è¿é€šæ€§åˆ†æ

ğŸ”§ **ä¾èµ–ç®¡ç†**:
- å¿…éœ€ï¼šnetworkx (å›¾ç®—æ³•åº“)
- GPUåŠ é€Ÿï¼šcudf, cugraph (RAPIDS GPUå›¾è®¡ç®—)
- CPU Leidenï¼špython-igraph, leidenalg
- è‡ªåŠ¨å›é€€ï¼šç¼ºå°‘ä¾èµ–æ—¶é™çº§åˆ°å¯ç”¨ç®—æ³•

ğŸ“Š **é€‚ç”¨åœºæ™¯**:
- å¤§è§„æ¨¡æ•°æ®é›†ï¼ˆ>10ä¸‡èŠ‚ç‚¹ï¼‰GPUåŠ é€Ÿæ•ˆæœæ˜¾è‘—
- é«˜è´¨é‡èšç±»éœ€æ±‚
- ç ”ç©¶å’Œç”Ÿäº§ç¯å¢ƒ
- å®æ—¶æˆ–è¿‘å®æ—¶èšç±»åº”ç”¨

âš™ï¸ **é…ç½®ç¤ºä¾‹**:
```yaml
cluster:
  engine: "networkx"
  method: "leiden"        # leiden/louvain/connected_components
  enable_gpu: true        # å¯ç”¨GPUåŠ é€Ÿ
  resolution: 1.0         # ç¤¾åŒºåˆ†è¾¨ç‡å‚æ•°
```
"""

from __future__ import annotations

import argparse
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
from functools import partial
from typing import Dict, List, Tuple, Optional
import warnings

import numpy as np
import pandas as pd
import networkx as nx
from networkx.algorithms import community

from ..utils.config import ensure_output_dir, load_config
from ..utils.io_utils import write_parquet
from ..utils.metrics import StatsRecorder

# å¿½ç•¥NetworkXæ¨¡å—å¯èƒ½äº§ç”Ÿçš„ç”¨æˆ·è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning, module='networkx')


def _is_gpu_graph_available() -> bool:
    """
    æ£€æŸ¥GPUå›¾è®¡ç®—ç¯å¢ƒå¯ç”¨æ€§
    
    Returns:
        bool: True if cuGraph/cudf å¯ç”¨ä¸”GPUç¯å¢ƒæ­£å¸¸
        
    æ£€æŸ¥é¡¹ç›®ï¼š
        - cudfåº“å¯ç”¨æ€§ï¼ˆGPU DataFrameæ“ä½œï¼‰
        - cugraphåº“å¯ç”¨æ€§ï¼ˆGPUå›¾ç®—æ³•ï¼‰
        - GPUè®¾å¤‡å¯ç”¨æ€§
        
    æ³¨æ„ï¼š
        æ­¤å‡½æ•°ä»…æ£€æŸ¥åº“çš„å¯¼å…¥ï¼Œä¸éªŒè¯GPUå†…å­˜æˆ–æ€§èƒ½
    """
    try:
        import cudf  # noqa: F401
        import cugraph  # noqa: F401
        # ç®€å•éªŒè¯GPUå¯ç”¨æ€§
        _ = cudf.DataFrame({'test': [1, 2, 3]})
        return True
    except Exception:
        return False


def _build_cugraph_graph(pairs_df: pd.DataFrame, threshold: float):
    """
    æ„å»ºGPUåŠ é€Ÿçš„æ— å‘å›¾ç”¨äºèšç±»ç®—æ³•
    
    Args:
        pairs_df: åŒ…å«èŠ‚ç‚¹å¯¹å’ŒCEåˆ†æ•°çš„DataFrameï¼Œåˆ—åä¸º['i', 'j', 'ce_final']
        threshold: CEåˆ†æ•°é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„è¾¹å°†è¢«è¿‡æ»¤
        
    Returns:
        cugraph.Graph: GPUå›¾å¯¹è±¡ï¼ŒåŒ…å«è¿‡æ»¤åçš„åŠ æƒè¾¹
        
    æ€§èƒ½ç‰¹ç‚¹ï¼š
        - GPUå†…å­˜ï¼šè¾¹æ•°æ®å®Œå…¨åŠ è½½åˆ°GPUå†…å­˜
        - è¿‡æ»¤ä¼˜åŒ–ï¼šåœ¨CPUç«¯å®Œæˆæ•°æ®è¿‡æ»¤ï¼Œå‡å°‘GPUä¼ è¾“
        - å›¾æ„å»ºï¼šä½¿ç”¨cuGraphåŸç”ŸAPIï¼Œå……åˆ†åˆ©ç”¨GPUå¹¶è¡Œ
        
    å†…å­˜è€ƒè™‘ï¼š
        - å¤§å›¾å¯èƒ½è¶…å‡ºGPUå†…å­˜é™åˆ¶
        - å»ºè®®ç›‘æ§GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
    """
    import cudf
    import cugraph

    # CPUç«¯è¿‡æ»¤ï¼Œå‡å°‘GPUä¼ è¾“å¼€é”€
    filtered_pairs = pairs_df[pairs_df['ce_final'] >= threshold][['i', 'j', 'ce_final']].copy()
    
    if len(filtered_pairs) == 0:
        raise ValueError(f"é˜ˆå€¼ {threshold} è¿‡æ»¤åæ— æœ‰æ•ˆè¾¹ï¼Œè¯·è°ƒæ•´é˜ˆå€¼")
    
    # æ ‡å‡†åŒ–åˆ—åä¸ºcuGraphæ ¼å¼
    filtered_pairs.rename(columns={'i': 'src', 'j': 'dst', 'ce_final': 'weight'}, inplace=True)
    
    # ä¼ è¾“åˆ°GPU
    edges_gdf = cudf.from_pandas(filtered_pairs)
    
    # æ„å»ºæ— å‘å›¾
    G = cugraph.Graph(directed=False)
    G.from_cudf_edgelist(edges_gdf, source='src', destination='dst', edge_attr='weight')
    
    print(f"[stage4] GPUå›¾æ„å»ºå®Œæˆ: {G.number_of_vertices()} èŠ‚ç‚¹, {G.number_of_edges()} è¾¹")
    return G


def _communities_from_partition_df(partition_df) -> List[List[int]]:
    """
    è½¬æ¢cuGraphåˆ†åŒºç»“æœä¸ºPythonç¤¾åŒºåˆ—è¡¨
    
    Args:
        partition_df: cuGraphç®—æ³•è¾“å‡ºçš„åˆ†åŒºDataFrameï¼ŒåŒ…å«['vertex', 'partition']åˆ—
        
    Returns:
        List[List[int]]: ç¤¾åŒºåˆ—è¡¨ï¼Œæ¯ä¸ªç¤¾åŒºåŒ…å«èŠ‚ç‚¹IDçš„æ’åºåˆ—è¡¨
        
    å¤„ç†é€»è¾‘ï¼š
        1. ä»GPUä¼ è¾“åˆ†åŒºç»“æœåˆ°CPU
        2. æŒ‰åˆ†åŒºIDåˆ†ç»„èŠ‚ç‚¹
        3. è¿‡æ»¤å•èŠ‚ç‚¹ç¤¾åŒºï¼ˆsize < 2ï¼‰
        4. æ’åºèŠ‚ç‚¹IDç¡®ä¿ç»“æœç¡®å®šæ€§
        
    æ€§èƒ½è€ƒè™‘ï¼š
        - GPU->CPUä¼ è¾“æœ‰å¼€é”€ï¼Œä½†ç»“æœé€šå¸¸è¾ƒå°
        - å†…å­˜ä½¿ç”¨ï¼šCPUç«¯ä¸´æ—¶å­˜å‚¨åˆ†åŒºç»“æœ
    """
    if partition_df is None or len(partition_df) == 0:
        return []
    
    # GPU->CPUä¼ è¾“
    pdf = partition_df.to_pandas()
    
    # æŒ‰åˆ†åŒºåˆ†ç»„å¹¶è½¬æ¢ä¸ºç¤¾åŒº
    groups = pdf.groupby('partition')['vertex'].apply(list)
    communities: List[List[int]] = []
    
    for partition_nodes in groups:
        if len(partition_nodes) >= 2:  # è¿‡æ»¤å•èŠ‚ç‚¹ç°‡
            # ç¡®ä¿èŠ‚ç‚¹IDä¸ºæ•´æ•°å¹¶æ’åº
            community = sorted([int(node) for node in partition_nodes])
            communities.append(community)
    
    return communities


def louvain_gpu(pairs_df: pd.DataFrame, threshold: float, resolution: float = 1.0) -> List[List[int]]:
    """
    GPUåŠ é€Ÿçš„Louvainç¤¾åŒºæ£€æµ‹ç®—æ³•
    
    Args:
        pairs_df: èŠ‚ç‚¹å¯¹CEåˆ†æ•°æ•°æ®
        threshold: è¾¹æƒé‡é˜ˆå€¼
        resolution: åˆ†è¾¨ç‡å‚æ•°ï¼Œæ§åˆ¶ç¤¾åŒºå¤§å°ï¼ˆè¶Šå¤§ç¤¾åŒºè¶Šå°ï¼‰
        
    Returns:
        List[List[int]]: æ£€æµ‹åˆ°çš„ç¤¾åŒºåˆ—è¡¨
        
    ç®—æ³•ç‰¹ç‚¹ï¼š
        - æ¨¡å—åº¦ä¼˜åŒ–ï¼šç»å…¸çš„ç¤¾åŒºæ£€æµ‹ç®—æ³•
        - GPUå¹¶è¡Œï¼šcuGraphå®ç°ï¼Œé€‚åˆå¤§è§„æ¨¡å›¾
        - åˆ†è¾¨ç‡è°ƒèŠ‚ï¼šæ”¯æŒç²¾ç¡®æ§åˆ¶ç¤¾åŒºç²’åº¦
        
    æ€§èƒ½ä¼˜åŠ¿ï¼š
        - ç›¸æ¯”CPU NetworkXï¼š10-100xåŠ é€Ÿï¼ˆå–å†³äºå›¾å¤§å°ï¼‰
        - å†…å­˜æ•ˆç‡ï¼šGPUå†…å­˜ç®¡ç†ä¼˜åŒ–
        - ç®—æ³•å¤æ‚åº¦ï¼šO(m log n)ï¼Œå…¶ä¸­mæ˜¯è¾¹æ•°
        
    æ³¨æ„äº‹é¡¹ï¼š
        - éœ€è¦è¶³å¤ŸGPUå†…å­˜å­˜å‚¨å›¾ç»“æ„
        - åˆ†è¾¨ç‡å‚æ•°å½±å“ç¤¾åŒºæ•°é‡å’Œè´¨é‡
    """
    import cugraph
    
    try:
        G = _build_cugraph_graph(pairs_df, threshold)
        
        # cuGraph Louvainæ”¯æŒåˆ†è¾¨ç‡å‚æ•°
        partition_df, modularity = cugraph.louvain(G, resolution=resolution)
        communities = _communities_from_partition_df(partition_df)
        
        print(f"[stage4] GPU Louvainå®Œæˆ: {len(communities)} ä¸ªç¤¾åŒº, "
              f"æ¨¡å—åº¦: {modularity:.4f}")
        return communities
        
    except Exception as e:
        raise RuntimeError(f"GPU Louvainèšç±»å¤±è´¥: {e}") from e


def leiden_gpu(pairs_df: pd.DataFrame, threshold: float, resolution: float = 1.0) -> List[List[int]]:
    """
    GPUåŠ é€Ÿçš„Leidenç¤¾åŒºæ£€æµ‹ç®—æ³•
    
    Args:
        pairs_df: èŠ‚ç‚¹å¯¹CEåˆ†æ•°æ•°æ®
        threshold: è¾¹æƒé‡é˜ˆå€¼  
        resolution: åˆ†è¾¨ç‡å‚æ•°ï¼Œæ§åˆ¶ç¤¾åŒºå¤§å°
        
    Returns:
        List[List[int]]: æ£€æµ‹åˆ°çš„ç¤¾åŒºåˆ—è¡¨
        
    ç®—æ³•ç‰¹ç‚¹ï¼š
        - å…ˆè¿›ç®—æ³•ï¼šå…‹æœLouvainç®—æ³•çš„å±€é™æ€§
        - è´¨é‡ä¿è¯ï¼šé¿å…è¿æ¥å·®çš„ç¤¾åŒº
        - GPUåŠ é€Ÿï¼šcuGraphé«˜æ€§èƒ½å®ç°
        
    æ€§èƒ½ä¼˜åŠ¿ï¼š
        - è´¨é‡æœ€é«˜ï¼šç›¸æ¯”Louvainæœ‰æ›´å¥½çš„ç¤¾åŒºè´¨é‡
        - GPUå¹¶è¡Œï¼šå¤§å›¾ä¸Šæ˜¾è‘—åŠ é€Ÿ
        - ç¨³å®šæ€§ï¼šç»“æœæ›´åŠ ç¨³å®šå’Œå¯é‡ç°
        
    å…¼å®¹æ€§ï¼š
        - éœ€è¦è¾ƒæ–°ç‰ˆæœ¬çš„cuGraphï¼ˆ>=21.10ï¼‰
        - è‡ªåŠ¨æ£€æµ‹APIå¯ç”¨æ€§
    """
    import cugraph
    
    # æ£€æŸ¥Leidenç®—æ³•å¯ç”¨æ€§
    if not hasattr(cugraph, 'leiden'):
        raise ImportError(
            'cuGraphä¸æ”¯æŒLeidenç®—æ³•ï¼Œè¯·å‡çº§åˆ°cuGraph>=21.10æˆ–ä½¿ç”¨Louvainç®—æ³•'
        )
    
    try:
        G = _build_cugraph_graph(pairs_df, threshold)
        
        # cuGraph Leidenç®—æ³•
        partition_df, modularity = cugraph.leiden(G, resolution=resolution)
        communities = _communities_from_partition_df(partition_df)
        
        print(f"[stage4] GPU Leidenå®Œæˆ: {len(communities)} ä¸ªç¤¾åŒº, "
              f"æ¨¡å—åº¦: {modularity:.4f}")
        return communities
        
    except Exception as e:
        raise RuntimeError(f"GPU Leidenèšç±»å¤±è´¥: {e}") from e


def connected_components_gpu(pairs_df: pd.DataFrame, threshold: float) -> List[List[int]]:
    """
    GPUåŠ é€Ÿçš„è¿é€šåˆ†é‡æ£€æµ‹ç®—æ³•
    
    Args:
        pairs_df: èŠ‚ç‚¹å¯¹CEåˆ†æ•°æ•°æ®
        threshold: è¾¹æƒé‡é˜ˆå€¼
        
    Returns:
        List[List[int]]: æ£€æµ‹åˆ°çš„è¿é€šåˆ†é‡åˆ—è¡¨
        
    ç®—æ³•ç‰¹ç‚¹ï¼š
        - åŸºç¡€å›¾ç®—æ³•ï¼šæŸ¥æ‰¾å›¾ä¸­çš„è¿é€šå­å›¾
        - GPUå¹¶è¡Œï¼šå¹¶è¡ŒUnion-Findæˆ–BFSå®ç°
        - ç¡®å®šæ€§ç»“æœï¼šç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡º
        
    æ€§èƒ½ä¼˜åŠ¿ï¼š
        - ç®€å•é«˜æ•ˆï¼šç®—æ³•å¤æ‚åº¦O(m+n)
        - GPUåŠ é€Ÿï¼šå¤§å›¾ä¸Šæ˜¾è‘—æ€§èƒ½æå‡
        - å†…å­˜å‹å¥½ï¼šç›¸æ¯”ç¤¾åŒºæ£€æµ‹ç®—æ³•å†…å­˜éœ€æ±‚æ›´å°‘
        
    é€‚ç”¨åœºæ™¯ï¼š
        - åŸºç¡€èšç±»éœ€æ±‚
        - å†…å­˜æˆ–æ—¶é—´å—é™ç¯å¢ƒ
        - ä½œä¸ºå…¶ä»–ç®—æ³•çš„é¢„å¤„ç†æ­¥éª¤
    """
    import cugraph
    
    try:
        G = _build_cugraph_graph(pairs_df, threshold)
        
        # cuGraphè¿é€šåˆ†é‡ç®—æ³•
        component_df = cugraph.connected_components(G)
        
        # ä½¿ç”¨é€šç”¨è½¬æ¢å‡½æ•°ï¼ˆè¿é€šåˆ†é‡ç»“æœæ ¼å¼ä¸åˆ†åŒºç›¸åŒï¼‰
        communities = _communities_from_partition_df(component_df)
        
        print(f"[stage4] GPUè¿é€šåˆ†é‡å®Œæˆ: {len(communities)} ä¸ªè¿é€šåˆ†é‡")
        return communities
        
    except Exception as e:
        raise RuntimeError(f"GPUè¿é€šåˆ†é‡è®¡ç®—å¤±è´¥: {e}") from e


def _leiden_cpu_clustering(G: nx.Graph, resolution: float = 1.0) -> List[List[int]]:
    """CPUç‰ˆæœ¬çš„Leidenèšç±»ç®—æ³•"""
    try:
        import igraph as ig
        import leidenalg
        
        # è½¬æ¢NetworkXå›¾åˆ°igraph
        edges = [(u, v, d['weight']) for u, v, d in G.edges(data=True)]
        ig_graph = ig.Graph.TupleList(edges, weights=True)
        
        # Leidenç®—æ³•
        partition = leidenalg.find_partition(ig_graph, leidenalg.RBConfigurationVertexPartition, resolution_parameter=resolution)
        
        # è½¬æ¢ç»“æœ
        communities = []
        for community in partition:
            communities.append([G.nodes()[i] for i in community])
        
        return communities
    except ImportError:
        raise ImportError("Leiden CPUéœ€è¦ä¾èµ–: pip install python-igraph leidenalg")


def _louvain_cpu_clustering(G: nx.Graph, resolution: float = 1.0) -> List[List[int]]:
    """CPUç‰ˆæœ¬çš„Louvainèšç±»ç®—æ³•"""
    from networkx.algorithms import community
    
    communities_gen = community.louvain_communities(G, resolution=resolution, weight='weight')
    return [list(community) for community in communities_gen]


def _connected_components_cpu_clustering(G: nx.Graph) -> List[List[int]]:
    """CPUç‰ˆæœ¬çš„è¿é€šåˆ†é‡ç®—æ³•"""
    import networkx as nx
    
    components = nx.connected_components(G)
    return [list(component) for component in components]


def _build_networkx_graph(pairs_df: pd.DataFrame, threshold: float) -> nx.Graph:
    """
    æ„å»ºNetworkXæ— å‘å›¾ç”¨äºé«˜çº§èšç±»ç®—æ³•
    
    Args:
        pairs_df: åŒ…å«èŠ‚ç‚¹å¯¹å’ŒCEåˆ†æ•°çš„DataFrame
        threshold: CEåˆ†æ•°é˜ˆå€¼ï¼Œè¿‡æ»¤ä½è´¨é‡è¿æ¥
        
    Returns:
        nx.Graph: NetworkXæ— å‘å›¾å¯¹è±¡ï¼ŒåŒ…å«æƒé‡ä¿¡æ¯
        
    ç‰¹ç‚¹ï¼š
        - è‡ªåŠ¨èŠ‚ç‚¹ç®¡ç†ï¼šæ·»åŠ è¾¹æ—¶è‡ªåŠ¨åˆ›å»ºèŠ‚ç‚¹
        - æƒé‡ä¿ç•™ï¼šè¾¹æƒé‡ç”¨äºåç»­çš„èšç±»ç®—æ³•
        - å†…å­˜ä¼˜åŒ–ï¼šæ‰¹é‡æ·»åŠ è¾¹å‡å°‘å›¾æ“ä½œå¼€é”€
        
    æ³¨æ„ï¼š
        - å›¾æ˜¯æ— å‘çš„ï¼Œé€‚åˆç¤¾åŒºæ£€æµ‹ç®—æ³•
        - è¾¹æƒé‡å¯¹Leiden/Louvainç®—æ³•çš„è´¨é‡è‡³å…³é‡è¦
        - å¤§å›¾æ„å»ºå¯èƒ½æ¶ˆè€—è¾ƒå¤šå†…å­˜
    """
    G = nx.Graph()
    
    # æ‰¹é‡æ„å»ºè¾¹åˆ—è¡¨ï¼Œå‡å°‘å›¾æ“ä½œå¼€é”€
    edges_to_add = []
    for i, j, s in zip(pairs_df['i'], pairs_df['j'], pairs_df['ce_final']):
        if s >= threshold:
            edges_to_add.append((int(i), int(j), {'weight': float(s)}))
    
    # æ‰¹é‡æ·»åŠ è¾¹ï¼Œè‡ªåŠ¨åˆ›å»ºèŠ‚ç‚¹
    G.add_edges_from(edges_to_add)
    print(f"[stage4] NetworkXå›¾æ„å»ºå®Œæˆ: {G.number_of_nodes()} èŠ‚ç‚¹, {G.number_of_edges()} è¾¹")
    return G


def leiden_clustering_parallel(G: nx.Graph, resolution: float = 1.0, n_jobs: int = None) -> List[List[int]]:
    """ä½¿ç”¨Leidenç®—æ³•è¿›è¡Œå¹¶è¡Œèšç±»

    ä¿®å¤ç‚¹ï¼šæ­£ç¡®çš„ NetworkX èŠ‚ç‚¹åˆ° igraph é¡¶ç‚¹çš„åŒå‘æ˜ å°„ï¼Œå¹¶æ˜¾å¼ä¼ é€’æƒé‡ã€‚
    """
    try:
        # å°è¯•ä½¿ç”¨leidenalgåº“ï¼ˆéœ€è¦é¢å¤–å®‰è£…ï¼‰
        import leidenalg
        import igraph as ig

        # NetworkXèŠ‚ç‚¹ -> igraphé¡¶ç‚¹ çš„æ˜ å°„ï¼ˆè¿ç»­æ•´æ•°ç´¢å¼•ï¼‰
        nodes = list(G.nodes())
        node_to_idx = {node: idx for idx, node in enumerate(nodes)}
        idx_to_node = {idx: node for node, idx in node_to_idx.items()}

        # è¾¹åˆ—è¡¨ï¼ˆä½¿ç”¨æ˜ å°„åçš„ç´¢å¼•ï¼‰
        remapped_edges = [(node_to_idx[u], node_to_idx[v]) for u, v in G.edges()]

        # æ„å»ºæœ‰å‘ï¼ˆæ— å‘ï¼‰å›¾å¹¶è®¾ç½®è¾¹æƒé‡
        ig_graph = ig.Graph(n=len(nodes), edges=remapped_edges)
        weights = [G[u][v]['weight'] for u, v in G.edges()]
        ig_graph.es['weight'] = weights

        # Leidenèšç±»ï¼ˆæ˜¾å¼ä½¿ç”¨åŠ æƒåˆ†åŒºï¼Œä¼ å…¥æƒé‡å±æ€§åï¼‰
        partition = leidenalg.find_partition(
            ig_graph,
            leidenalg.ModularityVertexPartition,
            resolution_parameter=resolution,
            weights='weight',
        )

        # è½¬æ¢å› NetworkX èŠ‚ç‚¹ID
        communities: List[List[int]] = []
        for community_nodes in partition:
            community = [idx_to_node[idx] for idx in community_nodes]
            if len(community) >= 2:  # è¿‡æ»¤å•èŠ‚ç‚¹ç°‡
                communities.append(sorted(community))

        print(f"[stage4] Leidenç®—æ³•å®Œæˆï¼Œå‘ç° {len(communities)} ä¸ªç¤¾åŒº")
        return communities

    except ImportError:
        print("[stage4] leidenalgåº“æœªå®‰è£…ï¼Œå›é€€åˆ°Louvainç®—æ³•")
        return louvain_clustering_parallel(G, resolution, n_jobs)


def louvain_clustering_parallel(G: nx.Graph, resolution: float = 1.0, n_jobs: int = None) -> List[List[int]]:
    """ä½¿ç”¨Louvainç®—æ³•è¿›è¡Œèšç±»"""
    try:
        # ä½¿ç”¨NetworkXå†…ç½®çš„Louvainç®—æ³•
        communities_generator = community.louvain_communities(G, resolution=resolution, 
                                                            weight='weight', seed=42)
        communities = [sorted(list(comm)) for comm in communities_generator if len(comm) >= 2]
        print(f"[stage4] Louvainç®—æ³•å®Œæˆï¼Œå‘ç° {len(communities)} ä¸ªç¤¾åŒº")
        return communities
        
    except Exception as e:
        print(f"[stage4] Louvainç®—æ³•å¤±è´¥: {e}ï¼Œå›é€€åˆ°è¿é€šåˆ†é‡")
        return connected_components_networkx(G)


def connected_components_networkx(G: nx.Graph) -> List[List[int]]:
    """ä½¿ç”¨NetworkXè¿é€šåˆ†é‡ç®—æ³•"""
    components = [sorted(list(comp)) for comp in nx.connected_components(G) if len(comp) >= 2]
    print(f"[stage4] è¿é€šåˆ†é‡ç®—æ³•å®Œæˆï¼Œå‘ç° {len(components)} ä¸ªè¿é€šåˆ†é‡")
    return components


def parallel_subgraph_clustering(G: nx.Graph, method: str = 'leiden', 
                                resolution: float = 1.0, n_jobs: int = None) -> List[List[int]]:
    """å¯¹å¤§å›¾è¿›è¡Œåˆ†å—å¹¶è¡Œèšç±»ï¼ˆCPUè·¯å¾„ï¼‰ã€‚"""
    if n_jobs is None:
        n_jobs = min(mp.cpu_count(), 8)
    
    # å¦‚æœå›¾ä¸å¤Ÿå¤§ï¼Œç›´æ¥ä¸²è¡Œå¤„ç†
    if G.number_of_nodes() < 1000:
        if method == 'leiden':
            return leiden_clustering_parallel(G, resolution)
        elif method == 'louvain':
            return louvain_clustering_parallel(G, resolution)
        else:
            return connected_components_networkx(G)
    
    print(f"[stage4] å¤§å›¾å¹¶è¡Œå¤„ç†: {G.number_of_nodes()} èŠ‚ç‚¹ï¼Œä½¿ç”¨ {n_jobs} ä¸ªè¿›ç¨‹")
    
    # å…ˆæ‰¾è¿é€šåˆ†é‡ï¼Œç„¶åå¹¶è¡Œå¤„ç†æ¯ä¸ªåˆ†é‡
    connected_comps = list(nx.connected_components(G))
    print(f"[stage4] å‘ç° {len(connected_comps)} ä¸ªè¿é€šåˆ†é‡")
    
    if len(connected_comps) <= 1:
        # åªæœ‰ä¸€ä¸ªå¤§è¿é€šåˆ†é‡ï¼Œä½¿ç”¨ä¸²è¡Œç®—æ³•
        if method == 'leiden':
            return leiden_clustering_parallel(G, resolution)
        elif method == 'louvain':
            return louvain_clustering_parallel(G, resolution)
        else:
            return connected_components_networkx(G)
    
    # å¹¶è¡Œå¤„ç†æ¯ä¸ªè¿é€šåˆ†é‡
    cluster_func = partial(_cluster_subgraph, method=method, resolution=resolution)
    
    all_clusters = []
    large_components = [comp for comp in connected_comps if len(comp) >= 10]
    small_components = [comp for comp in connected_comps if 2 <= len(comp) < 10]
    
    # å¤§åˆ†é‡å¹¶è¡Œå¤„ç†
    if large_components:
        with ProcessPoolExecutor(max_workers=n_jobs) as executor:
            subgraphs = [G.subgraph(comp).copy() for comp in large_components]
            futures = [executor.submit(cluster_func, subgraph) for subgraph in subgraphs]
            
            for future in as_completed(futures):
                clusters = future.result()
                all_clusters.extend(clusters)
    
    # å°åˆ†é‡ç›´æ¥ä½œä¸ºç°‡
    for comp in small_components:
        all_clusters.append(sorted(list(comp)))
    
    print(f"[stage4] å¹¶è¡Œèšç±»å®Œæˆï¼Œæ€»å…± {len(all_clusters)} ä¸ªç°‡")
    return all_clusters


def _cluster_subgraph(subgraph: nx.Graph, method: str, resolution: float) -> List[List[int]]:
    """å¯¹å­å›¾è¿›è¡Œèšç±»ï¼ˆCPUè·¯å¾„ï¼‰ã€‚"""
    if method == 'leiden':
        return leiden_clustering_parallel(subgraph, resolution)
    elif method == 'louvain':
        return louvain_clustering_parallel(subgraph, resolution)
    else:
        return connected_components_networkx(subgraph)


def choose_center_networkx(nodes: List[int], G: nx.Graph) -> int:
    """åŸºäºNetworkXå›¾é€‰æ‹©ä¸­å¿ƒç‚¹"""
    if len(nodes) == 1:
        return nodes[0]
    
    best, best_score = nodes[0], -1.0
    subgraph = G.subgraph(nodes)
    
    for node in nodes:
        if node not in subgraph:
            continue
        
        # è®¡ç®—è¯¥èŠ‚ç‚¹åˆ°å…¶ä»–èŠ‚ç‚¹çš„å¹³å‡æƒé‡
        neighbors = list(subgraph.neighbors(node))
        if not neighbors:
            continue
            
        weights = [subgraph[node][neighbor]['weight'] for neighbor in neighbors 
                  if neighbor in nodes and neighbor != node]
        
        if weights:
            avg_weight = float(np.mean(weights))
            if avg_weight > best_score:
                best_score = avg_weight
                best = node
    
    return best


def center_metrics_networkx(center: int, nodes: List[int], G: nx.Graph) -> Dict[str, float]:
    """åŸºäºNetworkXå›¾è®¡ç®—ä¸­å¿ƒç‚¹æŒ‡æ ‡"""
    subgraph = G.subgraph(nodes)
    
    if center not in subgraph:
        return {'coverage': 0.0, 'mean': 0.0, 'median': 0.0, 'p10': 0.0}
    
    neighbors = list(subgraph.neighbors(center))
    weights = [subgraph[center][neighbor]['weight'] for neighbor in neighbors 
              if neighbor in nodes and neighbor != center]
    
    if not weights:
        return {'coverage': 0.0, 'mean': 0.0, 'median': 0.0, 'p10': 0.0}
    
    arr = np.asarray(weights, dtype=float)
    coverage = float(len(weights) / max(1, len(nodes) - 1))
    
    return {
        'coverage': coverage,
        'mean': float(np.mean(arr)),
        'median': float(np.median(arr)),
        'p10': float(np.percentile(arr, 10)),
    }


def validate_cluster_networkx(nodes: List[int], G: nx.Graph, cons: Dict[str, float]) -> Tuple[bool, int, Dict[str, float]]:
    """åŸºäºNetworkXå›¾éªŒè¯ç°‡è´¨é‡"""
    center = choose_center_networkx(nodes, G)
    metrics = center_metrics_networkx(center, nodes, G)
    
    ok = (
        metrics['coverage'] >= cons.get('coverage', 0.85)
        and metrics['mean'] >= cons.get('mean', 0.85)
        and metrics['median'] >= cons.get('median', 0.845)
        and metrics['p10'] >= cons.get('p10', 0.80)
    )
    return ok, center, metrics


def validate_clusters_networkx_parallel(communities: List[List[int]], G: nx.Graph, 
                                      cons: Dict[str, float], min_cluster_size: int,
                                      n_jobs: int = None) -> List[Dict]:
    """å¹¶è¡ŒéªŒè¯NetworkXèšç±»ç»“æœ"""
    if n_jobs is None:
        n_jobs = min(mp.cpu_count(), len(communities))
    
    if len(communities) <= 10:
        return validate_clusters_networkx_serial(communities, G, cons, min_cluster_size)
    
    validate_func = partial(validate_single_community_networkx, G=G, cons=cons, 
                          min_cluster_size=min_cluster_size)
    
    with ThreadPoolExecutor(max_workers=n_jobs) as executor:
        futures = [executor.submit(validate_func, comm) for comm in communities]
        
        valid_clusters = []
        for future in as_completed(futures):
            result = future.result()
            if result:
                valid_clusters.extend(result)
    
    return valid_clusters


def validate_clusters_networkx_serial(communities: List[List[int]], G: nx.Graph, 
                                    cons: Dict[str, float], min_cluster_size: int) -> List[Dict]:
    """ä¸²è¡ŒéªŒè¯NetworkXèšç±»ç»“æœ"""
    valid_clusters = []
    
    for nodes in communities:
        if len(nodes) < min_cluster_size:
            continue
        
        ok, center, metrics = validate_cluster_networkx(nodes, G, cons)
        if not ok:
            # åŒç‚¹ç°‡ä¿æŠ¤
            pair_min = float(cons.get('pair_min_for_2_nodes', 0.86))
            subgraph = G.subgraph(nodes)
            
            kept_pairs = []
            for u, v, data in subgraph.edges(data=True):
                if data['weight'] >= pair_min:
                    kept_pairs.append([u, v])
            
            if not kept_pairs:
                continue
                
            for pair in kept_pairs:
                ok2, center2, metrics2 = validate_cluster_networkx(pair, G, cons)
                if ok2:
                    valid_clusters.append({'center': center2, 'members': pair, **metrics2})
            continue
            
        valid_clusters.append({'center': center, 'members': nodes, **metrics})
    
    return valid_clusters


def validate_single_community_networkx(nodes: List[int], G: nx.Graph, 
                                     cons: Dict[str, float], min_cluster_size: int) -> List[Dict]:
    """éªŒè¯å•ä¸ªNetworkXç¤¾åŒº"""
    if len(nodes) < min_cluster_size:
        return []
    
    ok, center, metrics = validate_cluster_networkx(nodes, G, cons)
    if not ok:
        # åŒç‚¹ç°‡ä¿æŠ¤
        pair_min = float(cons.get('pair_min_for_2_nodes', 0.86))
        subgraph = G.subgraph(nodes)
        
        kept_pairs = []
        for u, v, data in subgraph.edges(data=True):
            if data['weight'] >= pair_min:
                kept_pairs.append([u, v])
        
        if not kept_pairs:
            return []
        
        result = []
        for pair in kept_pairs:
            ok2, center2, metrics2 = validate_cluster_networkx(pair, G, cons)
            if ok2:
                result.append({'center': center2, 'members': pair, **metrics2})
        return result
    
    return [{'center': center, 'members': nodes, **metrics}]


def consistency_vote(i: int, j: int, emb_a: np.ndarray, emb_b: np.ndarray, emb_c: np.ndarray, 
                    std_max: float, cos_a: float, cos_b: float, cos_c: float, vote_2_of_3: bool) -> bool:
    """ä¸€è‡´æ€§æŠ•ç¥¨"""
    ca = float(np.dot(emb_a[i], emb_a[j]))
    cb = float(np.dot(emb_b[i], emb_b[j]))
    cc = float(np.dot(emb_c[i], emb_c[j]))
    votes = (1 if ca >= cos_a else 0) + (1 if cb >= cos_b else 0) + (1 if cc >= cos_c else 0)
    std = float(np.std([ca, cb, cc]))
    return ((votes >= 2) if vote_2_of_3 else (votes == 3)) and (std <= std_max)


def run(cfg_path: str, input_file: str = None, n_jobs: Optional[int] = None) -> None:
    """
    NetworkXå¼•æ“ä¸»å‡½æ•° - é«˜è´¨é‡ç¤¾åŒºå‘ç°èšç±»
    
    Args:
        cfg_path: é…ç½®æ–‡ä»¶è·¯å¾„
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆæœªä½¿ç”¨ï¼Œä¿æŒæ¥å£ä¸€è‡´æ€§ï¼‰
        n_jobs: å¹¶è¡Œè¿›ç¨‹æ•°ï¼Œ-1è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
        
    ç®—æ³•æµç¨‹ï¼š
        1. é…ç½®è§£æï¼šåŠ è½½NetworkXç‰¹å®šçš„èšç±»é…ç½®
        2. å›¾æ„å»ºï¼šæ„å»ºå¸¦æƒé‡çš„NetworkXæ— å‘å›¾
        3. ç®—æ³•é€‰æ‹©ï¼šæ ¹æ®é…ç½®é€‰æ‹©Leiden/Louvain/è¿é€šåˆ†é‡
        4. ç¤¾åŒºæ£€æµ‹ï¼šæ‰§è¡Œé€‰å®šçš„èšç±»ç®—æ³•
        5. å¹¶è¡ŒéªŒè¯ï¼šå¤šçº¿ç¨‹éªŒè¯ç°‡è´¨é‡
        6. äºŒæ¬¡èšåˆï¼šåŸºäºNetworkXå›¾çš„ç°‡é—´åˆå¹¶
        7. ç»“æœè¾“å‡ºï¼šç”Ÿæˆèšç±»ç»“æœå’Œç»Ÿè®¡ä¿¡æ¯
        
    ç®—æ³•ä¼˜åŠ¿ï¼š
        - Leidenç®—æ³•ï¼šæœ€å…ˆè¿›çš„ç¤¾åŒºæ£€æµ‹ï¼Œå…‹æœLouvainå±€é™
        - æ¨¡å—åº¦ä¼˜åŒ–ï¼šåŸºäºå›¾è®ºçš„ä¸¥æ ¼æ•°å­¦åŸºç¡€
        - åˆ†è¾¨ç‡è°ƒèŠ‚ï¼šæ§åˆ¶ç°‡çš„ç²’åº¦å’Œæ•°é‡
        - åŠ æƒå¤„ç†ï¼šå……åˆ†åˆ©ç”¨CEåˆ†æ•°æƒé‡ä¿¡æ¯
        
    æ€§èƒ½ç‰¹ç‚¹ï¼š
        - è´¨é‡æœ€é«˜ï¼šç›¸æ¯”è¿é€šåˆ†é‡æœ‰æ˜¾è‘—è´¨é‡æå‡
        - å†…å­˜éœ€æ±‚ï¼šç›¸å¯¹è¾ƒé«˜ï¼Œé€‚åˆå¤§å†…å­˜ç¯å¢ƒ
        - è®¡ç®—å¤æ‚åº¦ï¼šO(m log n)ï¼Œå…¶ä¸­mæ˜¯è¾¹æ•°ï¼Œnæ˜¯èŠ‚ç‚¹æ•°
        
    è¾“å‡ºæ–‡ä»¶ï¼š
        - clusters.parquet: é«˜è´¨é‡èšç±»ç»“æœ
        - stage_stats.json: åŒ…å«å›¾ç»Ÿè®¡å’Œç®—æ³•ä¿¡æ¯
        - å¯é€‰å›¾è¡¨: cluster_size_hist.png
    """
    cfg = load_config(cfg_path)
    out_dir = ensure_output_dir(cfg)
    stats = StatsRecorder(cfg.get('observe.stats_path', f"{out_dir}/stage_stats.json"))
    
    # è·å–å¹¶è¡Œé…ç½®ï¼ˆæ”¯æŒ -1 è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒï¼‰
    if n_jobs is None:
        cfg_n_jobs = cfg.get('cluster.n_jobs', -1)
        if cfg_n_jobs in (-1, 0, None):
            n_jobs = mp.cpu_count()
        else:
            try:
                n_jobs = int(cfg_n_jobs)
            except Exception:
                n_jobs = mp.cpu_count()
    n_jobs = max(1, min(n_jobs, mp.cpu_count()))
    
    # GPU/CPUè·¯å¾„é€‰æ‹©
    # é»˜è®¤å¼€å¯GPUåŠ é€Ÿï¼ˆè‹¥ç¯å¢ƒå¯ç”¨åˆ™ä½¿ç”¨ï¼Œä¸å¯ç”¨åˆ™è‡ªåŠ¨å›é€€ï¼‰
    enable_gpu_config = bool(cfg.get('cluster.enable_gpu', True))
    gpu_available = _is_gpu_graph_available()
    enable_gpu = enable_gpu_config and gpu_available
    
    # GPUçŠ¶æ€æ—¥å¿—
    if enable_gpu:
        print("[stage4] å¯ç”¨GPUåŠ é€Ÿèšç±»ç®—æ³•")
    else:
        if enable_gpu_config and not gpu_available:
            print("[stage4] GPUé…ç½®å·²å¯ç”¨ä½†GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUç®—æ³•")
        else:
            print("[stage4] ä½¿ç”¨CPUèšç±»ç®—æ³•")

    # è¯»å–è¾“å…¥æ•°æ®
    pairs = pd.read_parquet(f"{out_dir}/stage3_ranked_pairs.parquet")
    print(f"[stage4] åŠ è½½ {len(pairs)} ä¸ªç›¸ä¼¼å¯¹")
    
    # é€‰æ‹©èšç±»æ–¹æ³•
    cluster_method = cfg.get('cluster.method', 'leiden').lower()
    resolution = float(cfg.get('cluster.resolution', 1.0))
    use_parallel = cfg.get('cluster.use_parallel', True)
    
    # æ„å»ºå›¾
    high_th = float(cfg.get('rerank.thresholds.high', 0.83))
    G = _build_networkx_graph(pairs, high_th)
    print(f"[stage4] æ„å»ºå›¾å®Œæˆï¼ŒèŠ‚ç‚¹æ•°: {G.number_of_nodes()}, è¾¹æ•°: {G.number_of_edges()}")
    
    # æ‰§è¡Œèšç±»ï¼ˆGPUä¼˜å…ˆï¼Œè‡ªåŠ¨å›é€€ï¼‰
    if enable_gpu:
        try:
            if cluster_method == 'leiden':
                clusters = leiden_gpu(pairs, high_th, resolution)
            elif cluster_method == 'louvain':
                clusters = louvain_gpu(pairs, high_th, resolution)
            else:
                clusters = connected_components_gpu(pairs, high_th)
            print(f"[stage4] GPUèšç±»å®Œæˆï¼Œæ£€æµ‹åˆ° {len(clusters)} ä¸ªç¤¾åŒº")
        except Exception as e:
            print(f"[stage4] GPUèšç±»å¤±è´¥: {e}ï¼Œå›é€€åˆ°CPUç®—æ³•")
            enable_gpu = False
    
    if not enable_gpu:
        # CPUå›é€€èšç±»
        if cluster_method == 'leiden':
            try:
                import igraph as ig
                import leidenalg
                clusters = _leiden_cpu_clustering(G, resolution)
            except ImportError:
                print("[stage4] Leiden CPUä¾èµ–ç¼ºå¤±ï¼Œä½¿ç”¨Louvainç®—æ³•")
                clusters = _louvain_cpu_clustering(G, resolution)
        elif cluster_method == 'louvain':
            clusters = _louvain_cpu_clustering(G, resolution)
        else:
            clusters = _connected_components_cpu_clustering(G)
        print(f"[stage4] CPUèšç±»å®Œæˆï¼Œæ£€æµ‹åˆ° {len(clusters)} ä¸ªç¤¾åŒº")
    
    # èšç±»éªŒè¯å’Œè¿‡æ»¤
    min_cluster_size = int(cfg.get('cluster.min_cluster_size', 2))
    valid_clusters = [cluster for cluster in clusters if len(cluster) >= min_cluster_size]
    print(f"[stage4] è¿‡æ»¤åä¿ç•™ {len(valid_clusters)} ä¸ªæœ‰æ•ˆç¤¾åŒº")
    
    # å‡†å¤‡è¾“å‡ºæ•°æ® - æ¯è¡Œä»£è¡¨ä¸€ä¸ªèšç±»
    cluster_data = []
    for cluster_id, cluster in enumerate(valid_clusters):
        # é€‰æ‹©èšç±»ä¸­å¿ƒ - ä½¿ç”¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ä½œä¸ºä¸­å¿ƒï¼ˆå¯ä»¥åç»­ä¼˜åŒ–ä¸ºåº¦æ•°æœ€é«˜çš„èŠ‚ç‚¹ï¼‰
        center = cluster[0]
        if G and G.number_of_nodes() > 0:
            # å¦‚æœæœ‰å›¾ä¿¡æ¯ï¼Œé€‰æ‹©åº¦æ•°æœ€é«˜çš„èŠ‚ç‚¹ä½œä¸ºä¸­å¿ƒ
            degrees = {node: G.degree(node) for node in cluster if G.has_node(node)}
            if degrees:
                center = max(degrees.items(), key=lambda x: x[1])[0]
        
        cluster_data.append({
            'cluster_id': cluster_id,
            'center': int(center),
            'members': [int(node) for node in cluster],
            'size': len(cluster)
        })
    
    result_df = pd.DataFrame(cluster_data)
    
    # ä¿å­˜ç»“æœ
    write_parquet(result_df, f"{out_dir}/clusters.parquet")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats_dict = {
        'total_nodes': G.number_of_nodes() if G else len(set([item for sublist in clusters for item in sublist])),
        'total_edges': G.number_of_edges() if G else 0,
        'num_clusters': len(valid_clusters),
        'avg_cluster_size': float(np.mean([len(c) for c in valid_clusters])) if valid_clusters else 0.0,
        'max_cluster_size': int(max([len(c) for c in valid_clusters])) if valid_clusters else 0,
        'min_cluster_size': int(min([len(c) for c in valid_clusters])) if valid_clusters else 0,
        'cluster_method': cluster_method,
        'used_gpu': enable_gpu,
        'resolution': resolution
    }
    
    stats.update('stage4', stats_dict)
    
    print(f"[stage4] èšç±»å®Œæˆï¼Œç”Ÿæˆ {len(valid_clusters)} ä¸ªç¤¾åŒºï¼Œå¹³å‡å¤§å°: {stats_dict['avg_cluster_size']:.1f}")
    
    # ç®€åŒ–ç‰ˆæœ¬ï¼Œè·³è¿‡å¤æ‚çš„äºŒæ¬¡èšåˆ
    print("[stage4] NetworkXèšç±»å®Œæˆ")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='Stage4 èšç±»æ¨¡å— - NetworkXå¼•æ“ï¼ˆGPU/CPUæ··åˆåŠ é€Ÿç‰ˆæœ¬ï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ğŸš€ GPUåŠ é€Ÿç‰¹æ€§ï¼š
  âš¡ æ€§èƒ½æå‡ï¼šGPUåŠ é€Ÿ10-100xæ€§èƒ½æå‡ï¼ˆå¤§å›¾ï¼‰
  ğŸ”„ è‡ªåŠ¨å›é€€ï¼šGPUå¤±è´¥æ—¶æ— ç¼å›é€€åˆ°CPU
  ğŸ’¾ å†…å­˜ä¼˜åŒ–ï¼šæ™ºèƒ½GPUå†…å­˜ç®¡ç†
  ğŸ¯ é«˜ç²¾åº¦ï¼šä¿æŒCPUçº§åˆ«çš„èšç±»è´¨é‡

ğŸ“Š æ”¯æŒç®—æ³•ï¼š
  leiden        - æœ€å…ˆè¿›çš„ç¤¾åŒºæ£€æµ‹ï¼ˆæ¨èï¼ŒGPU/CPUï¼‰
  louvain       - ç»å…¸çš„æ¨¡å—åº¦ä¼˜åŒ–ï¼ˆGPU/CPUï¼‰
  connected_components - åŸºç¡€è¿é€šåˆ†é‡æ£€æµ‹ï¼ˆGPU/CPUï¼‰

ğŸ”§ ä¾èµ–è¦æ±‚ï¼š
  å¿…éœ€: networkx
  GPUåŠ é€Ÿ: cudf, cugraph (RAPIDS)
  CPU Leiden: python-igraph, leidenalg
        """
    )
    
    parser.add_argument(
        '--config', '-c',
        default='src/configs/config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: %(default)s)'
    )
    parser.add_argument(
        '--input', '-i',
        help='è¾“å…¥æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ï¼‰'
    )
    parser.add_argument(
        '--n-jobs', '-j',
        type=int,
        help='å¹¶è¡Œè¿›ç¨‹æ•°ï¼ˆ-1è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒï¼Œ0è¡¨ç¤ºè‡ªåŠ¨é€‰æ‹©ï¼‰'
    )
    
    args = parser.parse_args()
    run(args.config, args.input, args.n_jobs)
