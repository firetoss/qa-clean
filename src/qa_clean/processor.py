"""
QA æ•°æ®å¤„ç†å™¨
"""

import pandas as pd
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from sklearn.cluster import DBSCAN
from sklearn.metrics.pairwise import cosine_similarity
from .models import DualEmbeddingModel
from .vector_factory import create_vector_store, create_vector_index


class QAProcessor:
    """QA æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, topk: int, vector_store_type: str = "faiss_gpu", **kwargs):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            topk: ç›¸ä¼¼åº¦æœç´¢çš„top-kå€¼
            vector_store_type: å‘é‡å­˜å‚¨ç±»å‹ (faiss_gpu, pgvector)
            **kwargs: å…¶ä»–å‚æ•°
        """
        self.topk = topk
        self.vector_store_type = vector_store_type
        
        # åˆ›å»ºå‘é‡å­˜å‚¨
        self.vector_store = create_vector_store(vector_store_type, **kwargs)
        
        # åˆå§‹åŒ–åŒåµŒå…¥æ¨¡å‹
        self.embedding_model = DualEmbeddingModel(
            model_a_name="BAAI/bge-large-zh-v1.5",
            model_b_name="moka-ai/m3e-large",
            vector_store_type=vector_store_type,
            **kwargs
        )
        
        print(f"âœ… QA å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨ {vector_store_type} å­˜å‚¨")
    
    def process_qa_data(self, qa_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        å¤„ç†QAæ•°æ®
        
        Args:
            qa_data: QAæ•°æ®åˆ—è¡¨
            
        Returns:
            å¤„ç†ç»“æœ
        """
        print(f"ğŸ”„ å¼€å§‹å¤„ç† {len(qa_data)} æ¡QAæ•°æ®...")
        
        # æå–æ–‡æœ¬
        texts = [item.get('question', '') for item in qa_data]
        
        # æ’å…¥åˆ°å‘é‡å­˜å‚¨
        inserted_ids = self.embedding_model.insert_texts(texts, qa_data)
        
        # æ‰§è¡Œèšç±»
        clusters = self._perform_clustering(texts)
        
        # ç”Ÿæˆä»£è¡¨é—®é¢˜
        representative_questions = self._generate_representative_questions(texts, clusters)
        
        # å»é‡ç»“æœ
        dedup_results = self._deduplicate_qa_data(qa_data, clusters)
        
        return {
            'total_count': len(qa_data),
            'unique_count': len(dedup_results),
            'clusters': clusters,
            'representative_questions': representative_questions,
            'dedup_results': dedup_results
        }
    
    def _perform_clustering(self, texts: List[str], eps: float = 0.3, min_samples: int = 2) -> List[int]:
        """
        æ‰§è¡Œæ–‡æœ¬èšç±»
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            eps: DBSCANçš„epså‚æ•°
            min_samples: DBSCANçš„min_sampleså‚æ•°
            
        Returns:
            èšç±»æ ‡ç­¾åˆ—è¡¨
        """
        print("ğŸ”„ æ­£åœ¨æ‰§è¡Œæ–‡æœ¬èšç±»...")
        
        # ä½¿ç”¨æ¨¡å‹Aè¿›è¡Œèšç±»
        embeddings = self.embedding_model.model_a.encode(texts)
        
        # å½’ä¸€åŒ–å‘é‡
        embeddings_norm = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
        
        # æ‰§è¡ŒDBSCANèšç±»
        clustering = DBSCAN(eps=eps, min_samples=min_samples, metric='cosine')
        cluster_labels = clustering.fit_predict(embeddings_norm)
        
        # ç»Ÿè®¡èšç±»ç»“æœ
        unique_clusters = set(cluster_labels)
        noise_count = list(cluster_labels).count(-1)
        
        print(f"âœ… èšç±»å®Œæˆ: {len(unique_clusters) - (1 if -1 in unique_clusters else 0)} ä¸ªèšç±»ï¼Œ{noise_count} ä¸ªå™ªå£°ç‚¹")
        
        return cluster_labels.tolist()
    
    def _generate_representative_questions(self, texts: List[str], clusters: List[int]) -> Dict[int, str]:
        """
        ä¸ºæ¯ä¸ªèšç±»ç”Ÿæˆä»£è¡¨é—®é¢˜
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            clusters: èšç±»æ ‡ç­¾åˆ—è¡¨
            
        Returns:
            èšç±»IDåˆ°ä»£è¡¨é—®é¢˜çš„æ˜ å°„
        """
        print("ğŸ”„ æ­£åœ¨ç”Ÿæˆä»£è¡¨é—®é¢˜...")
        
        representative_questions = {}
        unique_clusters = set(clusters)
        
        for cluster_id in unique_clusters:
            if cluster_id == -1:  # è·³è¿‡å™ªå£°ç‚¹
                continue
            
            # è·å–è¯¥èšç±»çš„æ‰€æœ‰æ–‡æœ¬
            cluster_texts = [texts[i] for i, label in enumerate(clusters) if label == cluster_id]
            
            if len(cluster_texts) == 1:
                # å•ä¸ªæ–‡æœ¬ç›´æ¥ä½œä¸ºä»£è¡¨
                representative_questions[cluster_id] = cluster_texts[0]
            else:
                # å¤šä¸ªæ–‡æœ¬é€‰æ‹©æœ€çŸ­çš„ä½œä¸ºä»£è¡¨
                representative_questions[cluster_id] = min(cluster_texts, key=len)
        
        print(f"âœ… ç”Ÿæˆäº† {len(representative_questions)} ä¸ªä»£è¡¨é—®é¢˜")
        return representative_questions
    
    def _deduplicate_qa_data(self, qa_data: List[Dict[str, Any]], clusters: List[int]) -> List[Dict[str, Any]]:
        """
        åŸºäºèšç±»ç»“æœå»é‡QAæ•°æ®
        
        Args:
            qa_data: åŸå§‹QAæ•°æ®
            clusters: èšç±»æ ‡ç­¾åˆ—è¡¨
            
        Returns:
            å»é‡åçš„QAæ•°æ®
        """
        print("ğŸ”„ æ­£åœ¨æ‰§è¡Œæ•°æ®å»é‡...")
        
        # æŒ‰èšç±»åˆ†ç»„
        cluster_groups = {}
        for i, cluster_id in enumerate(clusters):
            if cluster_id not in cluster_groups:
                cluster_groups[cluster_id] = []
            cluster_groups[cluster_id].append(i)
        
        # ä¸ºæ¯ä¸ªèšç±»é€‰æ‹©ä»£è¡¨æ•°æ®
        dedup_results = []
        for cluster_id, indices in cluster_groups.items():
            if cluster_id == -1:  # å™ªå£°ç‚¹å•ç‹¬ä¿ç•™
                for idx in indices:
                    dedup_results.append(qa_data[idx])
            else:
                # é€‰æ‹©ç¬¬ä¸€ä¸ªä½œä¸ºä»£è¡¨
                dedup_results.append(qa_data[indices[0]])
        
        print(f"âœ… å»é‡å®Œæˆ: {len(qa_data)} -> {len(dedup_results)}")
        return dedup_results
    
    def search_similar_questions(self, query: str, topk: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        æœç´¢ç›¸ä¼¼é—®é¢˜
        
        Args:
            query: æŸ¥è¯¢é—®é¢˜
            topk: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            ç›¸ä¼¼é—®é¢˜åˆ—è¡¨
        """
        if topk is None:
            topk = self.topk
        
        return self.embedding_model.search_similar(query, topk)
    
    def batch_search_similar(self, queries: List[str], topk: Optional[int] = None) -> List[List[Dict[str, Any]]]:
        """
        æ‰¹é‡æœç´¢ç›¸ä¼¼é—®é¢˜
        
        Args:
            queries: æŸ¥è¯¢é—®é¢˜åˆ—è¡¨
            topk: æ¯ä¸ªæŸ¥è¯¢è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æ¯ä¸ªæŸ¥è¯¢çš„ç»“æœåˆ—è¡¨
        """
        if topk is None:
            topk = self.topk
        
        return self.embedding_model.batch_search(queries, topk)
    
    def close(self):
        """é‡Šæ”¾èµ„æº"""
        if hasattr(self.embedding_model, 'close'):
            self.embedding_model.close()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()
