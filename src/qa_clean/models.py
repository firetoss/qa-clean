"""
QA æ•°æ®æ¨¡å‹å’Œå‘é‡ç´¢å¼•ç®¡ç†å™¨
"""

import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from sentence_transformers import SentenceTransformer
from .vector_store import PGVectorStore, PGVectorIndex
from .faiss_store import FAISSGPUStore, FAISSGPUIndex


class DualEmbeddingModel:
    """åŒåµŒå…¥æ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self, model_a_name: str, model_b_name: str, vector_store_type: str = "faiss_gpu", **kwargs):
        """
        åˆå§‹åŒ–åŒåµŒå…¥æ¨¡å‹
        
        Args:
            model_a_name: æ¨¡å‹Aåç§°ï¼ˆå¦‚ bge-large-zhï¼‰
            model_b_name: æ¨¡å‹Båç§°ï¼ˆå¦‚ m3e-largeï¼‰
            vector_store_type: å‘é‡å­˜å‚¨ç±»å‹ (faiss_gpu, pgvector)
            **kwargs: å…¶ä»–å‚æ•°
        """
        self.model_a_name = model_a_name
        self.model_b_name = model_b_name
        self.vector_store_type = vector_store_type
        
        # åˆå§‹åŒ–æ¨¡å‹
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹ A: {model_a_name}")
        self.model_a = SentenceTransformer(model_a_name)
        
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹ B: {model_b_name}")
        self.model_b = SentenceTransformer(model_b_name)
        
        # åˆ›å»ºå‘é‡å­˜å‚¨
        self._create_vector_store(**kwargs)
        
        print("âœ… åŒåµŒå…¥æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
    
    def _create_vector_store(self, **kwargs):
        """åˆ›å»ºå‘é‡å­˜å‚¨"""
        if self.vector_store_type == "pgvector":
            from .vector_store import PGVectorStore
            self.vector_store = PGVectorStore(**kwargs)
        elif self.vector_store_type == "faiss_gpu":
            self.vector_store = FAISSGPUStore(**kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å‘é‡å­˜å‚¨ç±»å‹: {self.vector_store_type}")
    
    def encode_texts(self, texts: List[str]) -> Tuple[np.ndarray, np.ndarray]:
        """
        ç¼–ç æ–‡æœ¬ä¸ºå‘é‡
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            (embeddings_a, embeddings_b) å…ƒç»„
        """
        print(f"ğŸ”„ æ­£åœ¨ç¼–ç  {len(texts)} ä¸ªæ–‡æœ¬...")
        
        # ä½¿ç”¨æ¨¡å‹Aç¼–ç 
        embeddings_a = self.model_a.encode(texts, show_progress_bar=True)
        
        # ä½¿ç”¨æ¨¡å‹Bç¼–ç 
        embeddings_b = self.model_b.encode(texts, show_progress_bar=True)
        
        print(f"âœ… ç¼–ç å®Œæˆ: A={embeddings_a.shape}, B={embeddings_b.shape}")
        return embeddings_a, embeddings_b
    
    def insert_texts(self, texts: List[str], metadata: Optional[List[Dict[str, Any]]] = None) -> List[int]:
        """
        æ’å…¥æ–‡æœ¬åˆ°å‘é‡å­˜å‚¨
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            metadata: å…ƒæ•°æ®åˆ—è¡¨
            
        Returns:
            æ’å…¥çš„IDåˆ—è¡¨
        """
        # ç¼–ç æ–‡æœ¬
        embeddings_a, embeddings_b = self.encode_texts(texts)
        
        # æ’å…¥åˆ°å‘é‡å­˜å‚¨
        return self.vector_store.insert_vectors(texts, embeddings_a, embeddings_b, metadata)
    
    def search_similar(self, query: str, topk: int = 100, use_embedding: str = "a") -> List[Dict[str, Any]]:
        """
        æœç´¢ç›¸ä¼¼æ–‡æœ¬
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            topk: è¿”å›ç»“æœæ•°é‡
            use_embedding: ä½¿ç”¨å“ªä¸ªåµŒå…¥ ('a' æˆ– 'b')
            
        Returns:
            ç›¸ä¼¼æ–‡æœ¬åˆ—è¡¨
        """
        # ç¼–ç æŸ¥è¯¢æ–‡æœ¬
        if use_embedding == "a":
            query_vector = self.model_a.encode([query])[0]
        else:
            query_vector = self.model_b.encode([query])[0]
        
        # æœç´¢ç›¸ä¼¼å‘é‡
        results = self.vector_store.search_similar(query_vector, topk, use_embedding)
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        return [result[2] for result in results]
    
    def batch_search(self, queries: List[str], topk: int = 100, use_embedding: str = "a") -> List[List[Dict[str, Any]]]:
        """
        æ‰¹é‡æœç´¢ç›¸ä¼¼æ–‡æœ¬
        
        Args:
            queries: æŸ¥è¯¢æ–‡æœ¬åˆ—è¡¨
            topk: æ¯ä¸ªæŸ¥è¯¢è¿”å›ç»“æœæ•°é‡
            use_embedding: ä½¿ç”¨å“ªä¸ªåµŒå…¥
            
        Returns:
            æ¯ä¸ªæŸ¥è¯¢çš„ç»“æœåˆ—è¡¨
        """
        # ç¼–ç æŸ¥è¯¢æ–‡æœ¬
        if use_embedding == "a":
            query_vectors = self.model_a.encode(queries)
        else:
            query_vectors = self.model_b.encode(queries)
        
        # æ‰¹é‡æœç´¢
        batch_results = self.vector_store.batch_search(query_vectors, topk, use_embedding)
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        return [[result[2] for result in query_results] for query_results in batch_results]
    
    def get_vector_index(self, use_embedding: str = "a"):
        """è·å–å‘é‡ç´¢å¼•ï¼ˆå…¼å®¹FAISSæ¥å£ï¼‰"""
        if self.vector_store_type == "pgvector":
            return PGVectorIndex(self.vector_store, use_embedding)
        elif self.vector_store_type == "faiss_gpu":
            return FAISSGPUIndex(self.vector_store, use_embedding)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å‘é‡å­˜å‚¨ç±»å‹: {self.vector_store_type}")
    
    def close(self):
        """é‡Šæ”¾èµ„æº"""
        if hasattr(self.vector_store, 'close'):
            self.vector_store.close()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


class PGVectorIndexManager:
    """pgvector ç´¢å¼•ç®¡ç†å™¨ï¼ˆå…¼å®¹ FAISS æ¥å£ï¼‰"""
    
    def __init__(self, vector_store: PGVectorStore, use_embedding: str = "a"):
        self.vector_store = vector_store
        self.use_embedding = use_embedding
    
    def add(self, vectors: np.ndarray) -> None:
        """æ·»åŠ å‘é‡ï¼ˆå…¼å®¹ FAISS æ¥å£ï¼‰"""
        # è¿™é‡Œä¸»è¦æ˜¯ä¸ºäº†å…¼å®¹ FAISS æ¥å£
        pass
    
    def search(self, queries: np.ndarray, topk: int) -> Tuple[np.ndarray, np.ndarray]:
        """æœç´¢ï¼ˆå…¼å®¹ FAISS æ¥å£ï¼‰"""
        # è½¬æ¢ä¸º FAISS å…¼å®¹æ ¼å¼
        batch_results = self.vector_store.batch_search(queries, topk, self.use_embedding)
        
        similarities = []
        indices = []
        
        for query_results in batch_results:
            query_sims = []
            query_indices = []
            
            for result_id, similarity, _ in query_results:
                query_sims.append(similarity)
                query_indices.append(result_id)
            
            # å¡«å……åˆ° topk
            while len(query_sims) < topk:
                query_sims.append(0.0)
                query_indices.append(-1)
            
            similarities.append(query_sims[:topk])
            indices.append(query_indices[:topk])
        
        return np.array(similarities), np.array(indices)
    
    def reset(self) -> None:
        """é‡ç½®ç´¢å¼•"""
        pass
